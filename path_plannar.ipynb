{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pushkar-hue/MarsSimNav/blob/main/path_plannar.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ah1e762J2-kz"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import requests\n",
        "import zipfile\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "url = \"https://data.nasa.gov/docs/legacy/ai4mars-dataset-merged-0.1.zip\"\n",
        "zip_path = \"ai4mars-dataset.zip\"\n",
        "extract_dir = \"ai4mars-dataset\"\n",
        "\n",
        "# Download with progress bar\n",
        "def download_file(url, dest_path):\n",
        "    response = requests.get(url, stream=True)\n",
        "    total_size = int(response.headers.get('content-length', 0))\n",
        "    with open(dest_path, 'wb') as f, tqdm(\n",
        "        desc=dest_path,\n",
        "        total=total_size,\n",
        "        unit='iB',\n",
        "        unit_scale=True,\n",
        "        unit_divisor=1024,\n",
        "    ) as bar:\n",
        "        for chunk in response.iter_content(chunk_size=1024):\n",
        "            size = f.write(chunk)\n",
        "            bar.update(size)\n",
        "\n",
        "# Download if not already done\n",
        "if not os.path.exists(zip_path):\n",
        "    print(\"Downloading dataset...\")\n",
        "    download_file(url, zip_path)\n",
        "else:\n",
        "    print(\"ZIP file already downloaded.\")\n",
        "\n",
        "# Unzip\n",
        "if not os.path.exists(extract_dir):\n",
        "    print(\"Extracting...\")\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_dir)\n",
        "    print(\"Done.\")\n",
        "else:\n",
        "    print(\"Dataset already extracted.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WmtlXcuI3GMo"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "def walk_through(dir_path):\n",
        "  for dirpath, dirnames, filenames in os.walk(dir_path):\n",
        "    print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_eGHeSNq3PTi"
      },
      "outputs": [],
      "source": [
        "walk_through(extract_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1IOttEi73RYc"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "# Input paths\n",
        "root_dir = \"ai4mars-dataset/ai4mars-dataset-merged-0.1/msl\"\n",
        "images_dir = os.path.join(root_dir, \"images\", \"edr\")\n",
        "labels_dir = os.path.join(root_dir, \"labels\", \"train\")\n",
        "\n",
        "# Output paths\n",
        "subset_dir = \"ai4mars-subset\"\n",
        "subset_images = os.path.join(subset_dir, \"images\")\n",
        "subset_labels = os.path.join(subset_dir, \"labels\")\n",
        "\n",
        "# Make output dirs\n",
        "os.makedirs(subset_images, exist_ok=True)\n",
        "os.makedirs(subset_labels, exist_ok=True)\n",
        "\n",
        "# Build base filename sets\n",
        "image_dict = {f.rsplit(\".\", 1)[0]: f for f in os.listdir(images_dir) if f.lower().endswith(\".jpg\")}\n",
        "label_dict = {f.rsplit(\".\", 1)[0]: f for f in os.listdir(labels_dir) if f.lower().endswith(\".png\")}\n",
        "\n",
        "# Intersection of base names\n",
        "common_basenames = sorted(set(image_dict.keys()) & set(label_dict.keys()))\n",
        "print(f\"Found {len(common_basenames)} matched image-label pairs.\")\n",
        "\n",
        "# Select up to 5000\n",
        "subset_size = min(5000, len(common_basenames))\n",
        "subset_basenames = random.sample(common_basenames, subset_size)\n",
        "\n",
        "# Copy matched files\n",
        "print(f\"📦 Copying {subset_size} pairs to 'ai4mars-subset/'...\")\n",
        "for base in tqdm(subset_basenames):\n",
        "    shutil.copy(os.path.join(images_dir, image_dict[base]), os.path.join(subset_images, image_dict[base]))\n",
        "    shutil.copy(os.path.join(labels_dir, label_dict[base]), os.path.join(subset_labels, label_dict[base]))\n",
        "\n",
        "print(\" Subset creation complete!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0qA11jCU3S_S"
      },
      "outputs": [],
      "source": [
        "walk_through(subset_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BQ9q3q1g3U6E"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import networkx as nx\n",
        "from scipy.ndimage import distance_transform_edt\n",
        "from collections import deque\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torchvision\n",
        "import glob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KJRRmF2f45FM"
      },
      "outputs": [],
      "source": [
        "IMG_SIZE = 256\n",
        "TERRAIN_COSTS = {\n",
        "    0: 1,    # soil\n",
        "    1: 4,    # bedrock\n",
        "    2: 6,    # sand\n",
        "    3: 10,   # big rock\n",
        "    255: 100 # unlabeled (high cost)\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oYnhsVT35T3M"
      },
      "outputs": [],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sMw6QEVJ5C95"
      },
      "outputs": [],
      "source": [
        "def load_model(model_path=\"deeplabv3_mars.pth\"):\n",
        "    model = torchvision.models.segmentation.deeplabv3_resnet50(weights=None)\n",
        "    model.classifier = torchvision.models.segmentation.deeplabv3.DeepLabHead(2048, 4)\n",
        "\n",
        "    # Load full checkpoint\n",
        "    state_dict = torch.load(model_path, map_location=device)\n",
        "\n",
        "    # Filter out aux_classifier keys\n",
        "    filtered_dict = {k: v for k, v in state_dict.items() if not k.startswith(\"aux_classifier\")}\n",
        "\n",
        "    model.load_state_dict(filtered_dict, strict=False)\n",
        "\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oNV-REok8VVD"
      },
      "outputs": [],
      "source": [
        "def draw_mask(mask, title=\"Predicted Mask\"):\n",
        "    plt.figure(figsize=(6, 6))\n",
        "    plt.imshow(mask, cmap='gray')\n",
        "    plt.title(title)\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IBXzkiU56tKL"
      },
      "outputs": [],
      "source": [
        "def predict_mask(model, image_path):\n",
        "    transform = T.Compose([\n",
        "        T.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "        T.ToTensor(),\n",
        "        T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    img = Image.open(image_path).convert(\"RGB\")\n",
        "    input_tensor = transform(img).unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model(input_tensor)['out']\n",
        "        mask = output.argmax(1).squeeze().cpu().numpy()\n",
        "\n",
        "    return mask\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FkZ_2MC-7NjP"
      },
      "outputs": [],
      "source": [
        "def draw_path_on_original(image_path, mask, path):\n",
        "    img = Image.open(image_path).convert(\"RGB\").resize((IMG_SIZE, IMG_SIZE))\n",
        "    img_np = np.array(img)\n",
        "\n",
        "    # Draw path with gradient (blue to red)\n",
        "    for i in range(1, len(path)):\n",
        "        # Color changes from green (start) to red (goal)\n",
        "        r = int(255 * i/len(path))\n",
        "        g = int(255 * (1 - i/len(path)))\n",
        "        b = 0\n",
        "\n",
        "        # Draw thicker line for main path\n",
        "        cv2.line(img_np, (path[i-1][1], path[i-1][0]),\n",
        "                 (path[i][1], path[i][0]), (r, g, b), 3)\n",
        "\n",
        "        # Draw thinner highlight\n",
        "        cv2.line(img_np, (path[i-1][1], path[i-1][0]),\n",
        "                 (path[i][1], path[i][0]), (255, 255, 255), 1)\n",
        "\n",
        "    # Mark start (green) and end (red) points\n",
        "    cv2.circle(img_np, (path[0][1], path[0][0]), 10, (0, 255, 0), -1)\n",
        "    cv2.circle(img_np, (path[-1][1], path[-1][0]), 10, (255, 0, 0), -1)\n",
        "\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    plt.imshow(img_np)\n",
        "    plt.title(\"Optimized Rover Path (Red=Start, Green=Goal)\")\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RSkj9FXzCUb1"
      },
      "outputs": [],
      "source": [
        "def find_optimal_start_goal(cost_map):\n",
        "    \"\"\"Finds points near edges with lowest terrain cost\"\"\"\n",
        "    height, width = cost_map.shape\n",
        "    border = 20  # Distance from edge\n",
        "\n",
        "    # Left edge (start candidates)\n",
        "    left_col = cost_map[border:-border, border]\n",
        "    start_y = np.argmin(left_col) + border\n",
        "\n",
        "    # Right edge (goal candidates)\n",
        "    right_col = cost_map[border:-border, -border]\n",
        "    goal_y = np.argmin(right_col) + border\n",
        "\n",
        "    return (start_y, border), (goal_y, width-border)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j_7gi6zW5c5Q"
      },
      "outputs": [],
      "source": [
        "\n",
        "def convert_to_cost_map(mask):\n",
        "    cost_map = np.zeros_like(mask, dtype=np.float32)\n",
        "    for cls, cost in TERRAIN_COSTS.items():\n",
        "        cost_map[mask == cls] = cost\n",
        "    return cost_map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bu39lNcg9u3d"
      },
      "outputs": [],
      "source": [
        "\n",
        "def find_valid_point(cost_map, start_point, max_cost=10):\n",
        "    \"\"\"Find nearest point with cost <= max_cost using BFS\"\"\"\n",
        "    h, w = cost_map.shape\n",
        "    queue = deque([start_point])\n",
        "    visited = set([start_point])\n",
        "\n",
        "    while queue:\n",
        "        y, x = queue.popleft()\n",
        "        if cost_map[y, x] <= max_cost:\n",
        "            return (y, x)\n",
        "        for dy, dx in [(0,1), (0,-1), (1,0), (-1,0)]:\n",
        "            ny, nx = y + dy, x + dx\n",
        "            if 0 <= ny < h and 0 <= nx < w and (ny, nx) not in visited:\n",
        "                visited.add((ny, nx))\n",
        "                queue.append((ny, nx))\n",
        "    return start_point  # Fallback\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QXdU7ohR5g6E"
      },
      "outputs": [],
      "source": [
        "def build_graph(cost_map):\n",
        "    \"\"\"Create graph with edge weights based on terrain cost\"\"\"\n",
        "    h, w = cost_map.shape\n",
        "    G = nx.grid_2d_graph(h, w)\n",
        "\n",
        "    # Remove nodes in completely impassable terrain\n",
        "    for node in list(G.nodes):\n",
        "        if cost_map[node] >= 100:  # Unpassable terrain\n",
        "            G.remove_node(node)\n",
        "\n",
        "    # Add edge weights\n",
        "    for u, v in G.edges():\n",
        "        cost = (cost_map[u] + cost_map[v]) / 2\n",
        "        G.edges[u, v]['weight'] = cost\n",
        "\n",
        "    return G\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j-WYji7B5jZL"
      },
      "outputs": [],
      "source": [
        "def compute_path(cost_map, start, goal):\n",
        "    \"\"\"Compute path using A* algorithm with terrain awareness\"\"\"\n",
        "    # Create traversability map (1 where cost < 20)\n",
        "    traversable = (cost_map < 20).astype(np.float32)\n",
        "\n",
        "    # Calculate distance to obstacles\n",
        "    obstacle_dist = distance_transform_edt(traversable)\n",
        "\n",
        "    # Create graph with cost + distance penalty\n",
        "    adjusted_cost = cost_map + 20/(obstacle_dist + 1)\n",
        "\n",
        "    # Build graph with adjusted costs\n",
        "    G = build_graph(adjusted_cost)\n",
        "\n",
        "    # Verify start/goal are in graph\n",
        "    if start not in G or goal not in G:\n",
        "        return []\n",
        "\n",
        "    try:\n",
        "        return nx.astar_path(G, start, goal, weight='weight')\n",
        "    except:\n",
        "        return []\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tiD_NT5P5l5V"
      },
      "outputs": [],
      "source": [
        "def draw_path(mask, path):\n",
        "    vis = np.stack([mask]*3, axis=-1) * 60\n",
        "    for y, x in path:\n",
        "        vis[y, x] = [255, 0, 0]  # red path\n",
        "    plt.figure(figsize=(6, 6))\n",
        "    plt.imshow(vis)\n",
        "    plt.title(\"Planned Rover Path\")\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hFFbvyml5oCp"
      },
      "outputs": [],
      "source": [
        "def plan_rover_path(image_path, model):\n",
        "    mask = predict_mask(model, image_path)\n",
        "    cost_map = convert_to_cost_map(mask)\n",
        "\n",
        "    # Find valid start/goal points\n",
        "    start = find_valid_point(cost_map, (50, 50))\n",
        "    goal = find_valid_point(cost_map, (200, 200))\n",
        "\n",
        "    path = compute_path(cost_map, start, goal)\n",
        "\n",
        "    if not path:\n",
        "        print(\"⚠️ No valid path found - consider adjusting terrain costs\")\n",
        "        # Show cost map for debugging\n",
        "        plt.figure(figsize=(10, 10))\n",
        "        plt.imshow(cost_map, cmap='viridis')\n",
        "        plt.colorbar(label='Terrain Cost')\n",
        "        plt.title(\"Terrain Cost Map (No Path Found)\")\n",
        "        plt.axis(\"off\")\n",
        "        plt.show()\n",
        "    else:\n",
        "        print(f\"✅ Path found with {len(path)} steps\")\n",
        "        draw_path_on_original(image_path, mask, path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xO7uhBru5p7d"
      },
      "outputs": [],
      "source": [
        "model = load_model(\"deeplabv3_mars.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HcV99PQd5sYr"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import glob\n",
        "\n",
        "# Get all images\n",
        "image_files = glob.glob(\"/content/ai4mars-subset/images/*.JPG\")\n",
        "num_images = len(image_files)\n",
        "\n",
        "# Randomly pick 5 unique indices\n",
        "picked_indices = set()\n",
        "while len(picked_indices) < 5:\n",
        "    picked_indices.add(random.randint(0, num_images - 1))\n",
        "\n",
        "# Use the selected images\n",
        "for idx in picked_indices:\n",
        "    img_path = image_files[idx]\n",
        "    plan_rover_path(img_path, model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OggyQot26UG7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WoayTi8a6bj3"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyNAFAnbDqpOrCdiUvgAYeTz",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
